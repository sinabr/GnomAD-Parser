{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Download gnomAD files and genomic reference data\n",
    "Usage: python download_gnomad.py [--dry-run] [--chromosomes 1,2,X]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "class FileDownloader:\n",
    "    def __init__(self, dry_run=False):\n",
    "        self.dry_run = dry_run\n",
    "        self.failed_downloads = []\n",
    "        \n",
    "    def download_file(self, url: str, output_path: str) -> bool:\n",
    "        \"\"\"Download a file using wget with progress bar\"\"\"\n",
    "        if self.dry_run:\n",
    "            print(f\"[DRY RUN] Would download: {url}\")\n",
    "            return True\n",
    "            \n",
    "        # Check if file already exists\n",
    "        if os.path.exists(output_path):\n",
    "            file_size = os.path.getsize(output_path)\n",
    "            if file_size > 0:\n",
    "                print(f\"File exists ({file_size:,} bytes): {output_path}\")\n",
    "                return True\n",
    "        \n",
    "        print(f\"Downloading: {url}\")\n",
    "        try:\n",
    "            cmd = [\n",
    "                \"wget\",\n",
    "                \"-c\",  # Continue partial downloads\n",
    "                \"--progress=bar:force\",\n",
    "                \"-O\", output_path,\n",
    "                url\n",
    "            ]\n",
    "            result = subprocess.run(cmd, check=True)\n",
    "            return True\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"ERROR: Failed to download {url}\")\n",
    "            self.failed_downloads.append(url)\n",
    "            return False\n",
    "        except FileNotFoundError:\n",
    "            print(\"ERROR: wget not found. Please install wget.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Create directory structure\"\"\"\n",
    "    Path(\"exomes\").mkdir(exist_ok=True)\n",
    "    Path(\"genomes\").mkdir(exist_ok=True)\n",
    "    print(\"✓ Directory structure created\")\n",
    "\n",
    "def download_gnomad_files(downloader: FileDownloader, chromosomes: List[str]):\n",
    "    \"\"\"Download gnomAD exomes and genomes VCF files\"\"\"\n",
    "    \n",
    "    base_url = \"https://storage.googleapis.com/gcp-public-data--gnomad/release/4.1/vcf\"\n",
    "    \n",
    "    # Download exomes\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNLOADING GNOMAD EXOMES v4.1\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for chr_num in chromosomes:\n",
    "        print(f\"\\n--- Chromosome {chr_num} (Exomes) ---\")\n",
    "        \n",
    "        # VCF file\n",
    "        vcf_file = f\"gnomad.exomes.v4.1.sites.chr{chr_num}.vcf.bgz\"\n",
    "        vcf_url = f\"{base_url}/exomes/{vcf_file}\"\n",
    "        downloader.download_file(vcf_url, f\"exomes/{vcf_file}\")\n",
    "        \n",
    "        # Index file\n",
    "        tbi_file = f\"{vcf_file}.tbi\"\n",
    "        tbi_url = f\"{vcf_url}.tbi\"\n",
    "        downloader.download_file(tbi_url, f\"exomes/{tbi_file}\")\n",
    "    \n",
    "    # Download genomes\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNLOADING GNOMAD GENOMES v4.1\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for chr_num in chromosomes:\n",
    "        print(f\"\\n--- Chromosome {chr_num} (Genomes) ---\")\n",
    "        \n",
    "        # VCF file\n",
    "        vcf_file = f\"gnomad.genomes.v4.1.sites.chr{chr_num}.vcf.bgz\"\n",
    "        vcf_url = f\"{base_url}/genomes/{vcf_file}\"\n",
    "        downloader.download_file(vcf_url, f\"genomes/{vcf_file}\")\n",
    "        \n",
    "        # Index file\n",
    "        tbi_file = f\"{vcf_file}.tbi\"\n",
    "        tbi_url = f\"{vcf_url}.tbi\"\n",
    "        downloader.download_file(tbi_url, f\"genomes/{tbi_file}\")\n",
    "\n",
    "def download_reference_files(downloader: FileDownloader):\n",
    "    \"\"\"Download reference genome and annotation files\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNLOADING REFERENCE FILES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    files_to_download = [\n",
    "        # RefSeq gene files\n",
    "        (\n",
    "            \"https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/refseq_identifiers/refseqgene.1.genomic.fna.gz\",\n",
    "            \"refseqgene.1.genomic.fna.gz\"\n",
    "        ),\n",
    "        (\n",
    "            \"https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/refseq_identifiers/refseqgene.1.genomic.gbff.gz\",\n",
    "            \"refseqgene.1.genomic.gbff.gz\"\n",
    "        ),\n",
    "        # GRCh38 annotation files\n",
    "        (\n",
    "            \"https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/GRCh38_latest_genomic.gff.gz\",\n",
    "            \"GRCh38_latest_genomic.gff.gz\"\n",
    "        ),\n",
    "        (\n",
    "            \"https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/GRCh38_latest_rna.fna.gz\",\n",
    "            \"GRCh38_latest_rna.fna.gz\"\n",
    "        ),\n",
    "        # UniProt Swiss-Prot\n",
    "        (\n",
    "            \"https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\",\n",
    "            \"uniprot_sprot.fasta.gz\"\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    for url, filename in files_to_download:\n",
    "        print(f\"\\n--- {filename} ---\")\n",
    "        downloader.download_file(url, filename)\n",
    "    \n",
    "    # Optionally decompress GFF file\n",
    "    if os.path.exists(\"GRCh38_latest_genomic.gff.gz\") and not downloader.dry_run:\n",
    "        print(\"\\nDecompressing GRCh38_latest_genomic.gff.gz...\")\n",
    "        try:\n",
    "            subprocess.run([\"gunzip\", \"-f\", \"GRCh38_latest_genomic.gff.gz\"], check=True)\n",
    "            print(\"✓ Decompressed successfully\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"Warning: Failed to decompress GFF file\")\n",
    "\n",
    "def print_summary(downloader: FileDownloader):\n",
    "    \"\"\"Print download summary\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DOWNLOAD SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not downloader.dry_run:\n",
    "        exomes_count = len(list(Path(\"exomes\").glob(\"*\")))\n",
    "        genomes_count = len(list(Path(\"genomes\").glob(\"*\")))\n",
    "        ref_count = len([f for f in os.listdir(\".\") if f.endswith(('.gz', '.gff'))])\n",
    "        \n",
    "        print(f\"Exomes directory:  {exomes_count:3d} files\")\n",
    "        print(f\"Genomes directory: {genomes_count:3d} files\")\n",
    "        print(f\"Reference files:   {ref_count:3d} files\")\n",
    "    \n",
    "    if downloader.failed_downloads:\n",
    "        print(f\"\\n⚠ {len(downloader.failed_downloads)} downloads failed:\")\n",
    "        for url in downloader.failed_downloads:\n",
    "            print(f\"  - {url}\")\n",
    "    else:\n",
    "        print(\"\\n✓ All downloads completed successfully!\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Download gnomAD and reference genomic data\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dry-run\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Show what would be downloaded without actually downloading\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--chromosomes\",\n",
    "        type=str,\n",
    "        default=\"1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,X,Y\",\n",
    "        help=\"Comma-separated list of chromosomes to download (default: all)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--skip-gnomad\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Skip gnomAD files, only download reference files\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--skip-reference\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Skip reference files, only download gnomAD\"\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Parse chromosomes\n",
    "    chromosomes = [c.strip() for c in args.chromosomes.split(\",\")]\n",
    "    \n",
    "    print(\"gnomAD and Reference Data Downloader\")\n",
    "    print(f\"Chromosomes: {', '.join(chromosomes)}\")\n",
    "    print(f\"Dry run: {args.dry_run}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # Setup\n",
    "    setup_directories()\n",
    "    downloader = FileDownloader(dry_run=args.dry_run)\n",
    "    \n",
    "    # Download files\n",
    "    if not args.skip_gnomad:\n",
    "        download_gnomad_files(downloader, chromosomes)\n",
    "    \n",
    "    if not args.skip_reference:\n",
    "        download_reference_files(downloader)\n",
    "    \n",
    "    # Summary\n",
    "    print_summary(downloader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
